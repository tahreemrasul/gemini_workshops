{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4tLsHma1h5cJHF01CRiKH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tahreemrasul/gemini_workshops/blob/main/router_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a router agent using Gemini\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/tahreemrasul/gemini_workshops/blob/main/router_agent.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/tahreemrasul/gemini_workshops/blob/main/router_agent.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://raw.githubusercontent.com/primer/octicons/refs/heads/main/icons/mark-github-24.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>  "
      ],
      "metadata": {
        "id": "PhDfs3iLBDt6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Author |\n",
        "| --- |\n",
        "| [Tahreem Rasul](https://github.com/tahreemrasul/) |"
      ],
      "metadata": {
        "id": "zb94IBVGBL-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is a Router Agent?\n",
        "\n",
        "A router agent is an LLM that decides **which capability (tool)** should handle the user's request.  \n",
        "Instead of forcing the model into a single function, we give it a *choice*:\n",
        "\n",
        "- If the user asks a weather question â†’ route to the **weather tool**  \n",
        "- If the user asks a math question â†’ route to the **calculator tool**  \n",
        "- If neither tool makes sense â†’ answer normally, without tools  \n",
        "\n",
        "This is how more advanced agent frameworks (LangGraph, ADK, CrewAI) start to scale:\n",
        "the agent **classifies intent**, then **dispatches** the request to the right tool or sub-agent.\n",
        "\n",
        "In this notebook, we implement that idea using the [Google GenAI Python SDK](https://pypi.org/project/google-genai/), so you can see exactly how a router works under the hood without any frameworks.\n",
        "\n",
        "---\n",
        "\n",
        "### What We Will Build\n",
        "\n",
        "We'll create:\n",
        "\n",
        "1. **Two tools**  \n",
        "   - `get_weather(city)`  \n",
        "   - `calculate(expression)`\n",
        "\n",
        "2. **A system instruction** that teaches Gemini:  \n",
        "   *â€œUse the weather tool for weather queries, use the calculator tool for math, otherwise answer directly.â€*\n",
        "\n",
        "3. **A small agent loop** that:\n",
        "   - sends the user message + tools to Gemini  \n",
        "   - checks if the model wants to call a tool  \n",
        "   - executes the tool in Python  \n",
        "   - sends the result back to Gemini as a function response  \n",
        "   - prints the final answer  \n",
        "\n",
        "---\n",
        "\n",
        "By the end of the notebook, you should know how\n",
        "\n",
        "- to expose **multiple tools** to Gemini using the GenAI SDK  \n",
        "- to write a **router-style system prompt**  \n",
        "- the model chooses between tools based on intent  \n",
        "- to implement a **manual function-calling agent loop**  \n",
        "- routing is the foundation of more advanced multi-agent systems\n",
        "\n",
        "\n",
        "Let's build it. ðŸš€\n"
      ],
      "metadata": {
        "id": "2ildvch4BeQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started"
      ],
      "metadata": {
        "id": "1qj-BxQDTagz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install & Import Dependencies"
      ],
      "metadata": {
        "id": "O892najYPZqL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ9LZeVZOCuZ"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "from typing import Dict\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "print(\"google-genai version:\", genai.__version__)"
      ],
      "metadata": {
        "id": "thRMSX5BPf79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get API Key\n",
        "\n",
        "There are a few different ways of accessing the Gemini models in your applications. Most notably, you can do this through Vertex AI in Google Cloud Platform, or via the API method using Google AI Studio. We will be using the second approach.\n",
        "\n",
        "Head over to https://aistudio.google.com/ and generate an API Key.\n",
        "1. Click on **API Keys** on the left sidebar.\n",
        "2. You should now see an option to **Create API Key**. Click on this.\n",
        "3. A dialog box will open. You will be prompted to enter the name of the key. Enter a name of your choice. You also need to link this to a Google Cloud Project. From the dropdown of project selection, select **Create project**. You will be prompted to name the project, choose a name of your choice. Click on **Create Key**.\n",
        "4. You should now see your created API key in the list. Click on the key and copy it. Paste it in the cell below.\n"
      ],
      "metadata": {
        "id": "haJFf24ZxpS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ”‘ Paste your API key from Google AI Studio\n",
        "API_KEY = \"your-api-key\"\n",
        "\n",
        "from google import genai\n",
        "client = genai.Client(api_key=API_KEY)"
      ],
      "metadata": {
        "id": "Eop8m3uZzZHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5671450907ec"
      },
      "source": [
        "### Choose a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41e499d90618"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.5-flash\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UkHPHyEACO8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the agent"
      ],
      "metadata": {
        "id": "7zFXeOerTf2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 - Define the weather and calculator tools\n",
        "\n",
        "\n",
        "The weather tool will return the hard-coded values for a few cities. In a real app, this would call a live weather API. We'll add a second tool `calculate` that takes a simple math expression string, like `\"2 + 3 * 4\"` and outputs a JSON with `result` and an optional `error`.:\n",
        "\n",
        "\n",
        "Then we describe it to Gemini using a **FunctionDeclaration** + **Tool**, so the\n",
        "model knows:\n",
        "\n",
        "- the tool name\n",
        "- what it does\n",
        "- what parameters it expects"
      ],
      "metadata": {
        "id": "pjQAwLK2QlBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weather_impl(city: str) -> Dict:\n",
        "    \"\"\"Mock weather function.\n",
        "\n",
        "    In a real app, this would call an external API.\n",
        "    Here we just return fake but structured data.\n",
        "    \"\"\"\n",
        "    fake_temps = {\n",
        "        \"berlin\": {\"temperature_c\": 17, \"condition\": \"cloudy\"},\n",
        "        \"london\": {\"temperature_c\": 15, \"condition\": \"windy\"},\n",
        "        \"lahore\": {\"temperature_c\": 32, \"condition\": \"hot\"},\n",
        "        \"islamabad\": {\"temperature_c\": 28, \"condition\": \"warm and clear\"},\n",
        "        \"paris\": {\"temperature_c\": 19, \"condition\": \"light rain\"},\n",
        "    }\n",
        "\n",
        "    city_key = city.lower()\n",
        "    # return default fallback\n",
        "    data = fake_temps.get(\n",
        "        city_key,\n",
        "        {\"temperature_c\": 22, \"condition\": \"mild and unknown\"},\n",
        "    )\n",
        "    return {\n",
        "        \"city\": city,\n",
        "        \"temperature_c\": data[\"temperature_c\"],\n",
        "        \"condition\": data[\"condition\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "g4JIWKibQbFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, Dict\n",
        "\n",
        "def calculate_impl(expression: str) -> Dict[str, Any]:\n",
        "    \"\"\"Very simple calculator for demo purposes.\n",
        "\n",
        "    Evaluates a basic Python arithmetic expression.\n",
        "    DO NOT use this pattern in production.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # extremely constrained eval â€“ still just for demo\n",
        "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
        "        return {\"ok\": True, \"result\": result}\n",
        "    except Exception as e:\n",
        "        return {\"ok\": False, \"error\": str(e)}"
      ],
      "metadata": {
        "id": "spkhy9PuDozd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now describe the functions to the model."
      ],
      "metadata": {
        "id": "1fic2FEVQ_Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_weather_decl = types.FunctionDeclaration(\n",
        "    name=\"get_weather\",\n",
        "    description=\"Get the current (mock) weather for a given city.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"city\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"City name, e.g. 'London' or 'Lahore'.\",\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"city\"],\n",
        "    },\n",
        ")\n",
        "\n",
        "calculate_decl = types.FunctionDeclaration(\n",
        "    name=\"calculate\",\n",
        "    description=\"Evaluate a simple math expression, like '2 + 3 * 4'.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"expression\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Math expression in Python syntax, e.g. '2 + 3 * 4'.\",\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"expression\"],\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "juIxPfwtRAOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we bundle both tools into one Tool object the model can choose from."
      ],
      "metadata": {
        "id": "OxI_RTkwRGUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "router_tool = types.Tool(\n",
        "    function_declarations=[\n",
        "        get_weather_decl,\n",
        "        calculate_decl,\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "lB4SHn01RM41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2 â€” Router-style system instruction\n",
        "\n",
        "We want to bias Gemini to behave like a router:\n",
        "\n",
        "- If query is weather-ish â†’ call get_weather\n",
        "- If query is math-ish â†’ call calculate\n",
        "- Otherwise â†’ answer directly (no tool)\n",
        "\n",
        "We will do this with a system instruction telling Gemini to route query requests to relevant tools."
      ],
      "metadata": {
        "id": "2L2W53DiRQGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROUTER_SYSTEM_INSTRUCTION = \"\"\"\n",
        "You are a routing agent.\n",
        "\n",
        "Your job:\n",
        "- Decide whether the user question is about WEATHER or about MATH.\n",
        "- If it's about the weather in a specific city, call the `get_weather` function.\n",
        "- If it's a math question (calculations, expressions), call the `calculate` function.\n",
        "- If neither tool is appropriate, answer the question directly as a normal assistant.\n",
        "\n",
        "Always prefer using a tool when it matches the user's intent.\n",
        "When you use a tool, do NOT invent values â€“ rely on the tool result.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "gYTaj8xxEIha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 â€” Build the agent loop\n",
        "\n",
        "We will now code a loop that does the following per turn:\n",
        "\n",
        "1. Send user input + system instruction + tools.\n",
        "2. If the model asks for a tool:\n",
        "   - If `get_weather` â†’ call `get_weather_impl`.\n",
        "   - If `calculate` â†’ call `calculate_impl`.\n",
        "   - Send tool result back as a function response.\n",
        "3. Print final answer.\n",
        "\n",
        "Try with the following queries:\n",
        "- What's the weather like in Berlin today? â†’ should route to get_weather\n",
        "- What is 12 * (3 + 4)? â†’ should route to calculate\n",
        "- Give me a tip for staying focused while studying. â†’ answer directly, no tool\n",
        "- whats 40 plus 80"
      ],
      "metadata": {
        "id": "Js93YEK0R94I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_router_agent():\n",
        "    print(\"Router agent. Type 'exit' to quit.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.strip().lower() in {\"exit\", \"quit\", \"q\"}:\n",
        "            print(\"ðŸ‘‹ Bye!\")\n",
        "            break\n",
        "\n",
        "        # 1) Ask the model what to do, with tools + router instruction\n",
        "        response = client.models.generate_content(\n",
        "            model=MODEL_ID,\n",
        "            contents=[user_input],\n",
        "            config=types.GenerateContentConfig(\n",
        "                tools=[router_tool],\n",
        "                system_instruction=ROUTER_SYSTEM_INSTRUCTION,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # If no function calls, just print the text\n",
        "        if not response.function_calls:\n",
        "            print(\"Agent (no tool):\", response.text)\n",
        "            print(\"-\" * 60)\n",
        "            continue\n",
        "\n",
        "        # 2) Handle the first requested tool call\n",
        "        tool_call = response.function_calls[0]\n",
        "        print(f\"[debug] Router chose tool: {tool_call.name} with args {tool_call.args}\")\n",
        "\n",
        "        tool_result = None\n",
        "\n",
        "        if tool_call.name == \"get_weather\":\n",
        "            city = tool_call.args.get(\"city\", \"\")\n",
        "            tool_result = get_weather_impl(city=city)\n",
        "\n",
        "        elif tool_call.name == \"calculate\":\n",
        "            expr = tool_call.args.get(\"expression\", \"\")\n",
        "            tool_result = calculate_impl(expression=expr)\n",
        "\n",
        "        else:\n",
        "            # Unknown tool â€“ fallback: answer directly\n",
        "            print(\"[warn] Unknown tool, falling back to direct answer.\")\n",
        "            print(\"Agent:\", response.text)\n",
        "            print(\"-\" * 60)\n",
        "            continue\n",
        "\n",
        "        # Wrap the tool result as a function response part\n",
        "        function_response_part = types.Part.from_function_response(\n",
        "            name=tool_call.name,\n",
        "            response=tool_result,\n",
        "        )\n",
        "\n",
        "        # 3) Second turn: send user + tool result back to the model\n",
        "        followup_response = client.models.generate_content(\n",
        "            model=MODEL_ID,\n",
        "            contents=[\n",
        "                user_input,\n",
        "                function_response_part,\n",
        "            ],\n",
        "            config=types.GenerateContentConfig(\n",
        "                tools=[router_tool],\n",
        "                system_instruction=ROUTER_SYSTEM_INSTRUCTION,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        print(\"Agent:\", followup_response.text)\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "run_router_agent()"
      ],
      "metadata": {
        "id": "v32jJOZsSFhh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}